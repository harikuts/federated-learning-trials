{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FederatedLearningRepro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMnCo8gAbxcqBuVY66nEz+a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harikuts/federated-learning-trials/blob/master/FederatedLearningRepro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cwDfXm8MvnQ",
        "colab_type": "text"
      },
      "source": [
        "# Overview\n",
        "\n",
        "This notebook contains the reproduction of results of the original paper on federated learning.\n",
        "\n",
        "## Plan\n",
        "\n",
        "The roadmap for development is as follows:\n",
        "*   Construct standard MNIST example.\n",
        "*   To be continued.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyPkp1yZz527",
        "colab_type": "text"
      },
      "source": [
        "# Standard MNIST Example\n",
        "\n",
        "A standard MNIST example from Keras (https://keras.io/examples/mnist_cnn/) is used as a basis to compare our fedeerated model to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZTFxB_IMMGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "import pdb\n",
        "\n",
        "# Configuration\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# pdb.set_trace()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXAJn845_4rV",
        "colab_type": "text"
      },
      "source": [
        "# Federated Mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X5oARzu_1WB",
        "colab_type": "code",
        "outputId": "61e3c57d-1bc0-49b1-97ef-b651eaddccca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import random\n",
        "import pdb\n",
        "\n",
        "# Configuration\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "num_clients = 10 \n",
        "\n",
        "# mnist_train = tfds.load(name=\"mnist\", split=\"train\")\n",
        "# mnist_train = mnist_train.repeat().shuffle(1024).batch(32)\n",
        "# mnist_train = mnist_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "# mnist_test, info = tfds.load(\"mnist\", split=\"test\", with_info=True)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Splitting the dataset for different clients\n",
        "nonIID = True\n",
        "if nonIID:\n",
        "  percentageMarkers = []\n",
        "  for i in range(num_clients-1):\n",
        "    percentageMarkers.append(random.random())\n",
        "  percentageMarkers.append(1.0)\n",
        "  percentageMarkers = sorted(percentageMarkers)\n",
        "else:\n",
        "  percentageMarkers = [1/num_clients * (n+1) for n in range(num_clients)]\n",
        "\n",
        "# pdb.set_trace()\n",
        "\n",
        "client_x_trains = []\n",
        "client_y_trains = []\n",
        "xMarkers = [int(marker * len(x_train)) for marker in percentageMarkers]\n",
        "yMarkers = [int(marker * len(y_train)) for marker in percentageMarkers]\n",
        "pdb.set_trace()\n",
        "for j in range(len(percentageMarkers)):\n",
        "  client_x_trains.append(x_train[(xMarkers[j-1] if j > 0 else 0):xMarkers[j]])\n",
        "  client_x_trains.append(x_train[(yMarkers[j-1] if j > 0 else 0):yMarkers[j]])\n",
        "\n",
        "pdb.set_trace()\n",
        "\n",
        "# Model creation function\n",
        "def createCNN():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                  activation='relu',\n",
        "                  input_shape=input_shape))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adadelta(),\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--Return--\n",
            "> <ipython-input-6-af4b76dd72dd>(38)<module>()->None\n",
            "-> pdb.set_trace()\n",
            "(Pdb) xMarkers\n",
            "[1958, 2687, 4233, 13134, 15022, 22310, 33457, 38854, 51994, 60000]\n",
            "(Pdb) yMarkers\n",
            "[1958, 2687, 4233, 13134, 15022, 22310, 33457, 38854, 51994, 60000]\n",
            "(Pdb) c\n",
            "--Return--\n",
            "> <ipython-input-6-af4b76dd72dd>(43)<module>()->None\n",
            "-> pdb.set_trace()\n",
            "(Pdb) c\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}