{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DecentralizedLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMS0UIgr2S+W+ZfywJjbfeg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harikuts/federated-learning-trials/blob/master/DecentralizedLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cwDfXm8MvnQ",
        "colab_type": "text"
      },
      "source": [
        "# Overview\n",
        "\n",
        "This notebook contains the reproduction of results of the original paper on federated learning.\n",
        "\n",
        "## Plan\n",
        "\n",
        "The roadmap for development is as follows:\n",
        "*   Construct standard MNIST example.\n",
        "*   To be continued.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yo88uRHNvJq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "973a984c-caea-44f6-ba05-84a8205e8ca7"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "# !pip install tensorflow==2.1-rc0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0-rc0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyPkp1yZz527",
        "colab_type": "text"
      },
      "source": [
        "# Standard MNIST\n",
        "\n",
        "There are baseline implementations of a standard example of MNIST. A Keras implementation staands as the first example, but we will port this over to Tensorflow as it provides more low-level functionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D12oVhOOc1gp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "e1e4547e-4935-46e6-f6b7-bb04f7d59ad1"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# tf.enable_eager_execution()\n",
        "\n",
        "# Import MNIST data\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Create model\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Predictions\n",
        "predictions = model(x_train[:1]).numpy()\n",
        "# Softmax\n",
        "tf.nn.softmax(predictions).numpy()\n",
        "\n",
        "# Defining the loss function\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "loss_fn(y_train[:1], predictions).numpy()\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'], validation_data=(x_test, y_test))\n",
        "\n",
        "# Fit model\n",
        "model.fit(x_train, y_train, epochs=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer flatten_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e37636938962>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Compile model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0munknown_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m       raise TypeError(\n\u001b[0;32m--> 312\u001b[0;31m           'Invalid keyword argument(s) in `compile`: %s' % (unknown_kwargs,))\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid keyword argument(s) in `compile`: {'validation_data'}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce4iHoknf_cE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a6f95f24-47e1-419d-e9e3-ae1b4b89a600"
      },
      "source": [
        "# print(model.get_weights()[0].shape)\n",
        "# print(model.get_weights()[1].shape)\n",
        "# print(model.get_weights()[2].shape)\n",
        "# print(model.get_weights()[3].shape)\n",
        "\n",
        "import numpy as np\n",
        "a = np.array([1, 2, 3, 4])\n",
        "\n",
        "b = a + a\n",
        "b = sum([a,a])\n",
        "print(b)\n",
        "b = b / 2\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 4 6 8]\n",
            "[1. 2. 3. 4.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXAJn845_4rV",
        "colab_type": "text"
      },
      "source": [
        "# Experimental Approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SadZL91jeLg2",
        "colab_type": "text"
      },
      "source": [
        "## Customization Functions\n",
        "\n",
        "In this section, you can develop and select the dataset and models you want to use.\n",
        "\n",
        "Please note that your selected dataset and selected model must be comaptible (check input and output layers on the model).\n",
        "\n",
        "**The modules in this section must be run before running the experiments as they contain dataset and model building functions.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhf7oA8DompE",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Grab Functions\n",
        "\n",
        "Develop dataset functions here, including any pre-processing that needs to be done. Then set `get_dataset()` to utilize your function of  choice.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhO5fdctorYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pdb\n",
        "\n",
        "# Use this function to select one of the dataset grab functions\n",
        "def get_dataset():\n",
        "  return get_mnist()\n",
        "\n",
        "# MNIST Dataset\n",
        "def get_mnist():\n",
        "  # Import MNIST data\n",
        "  print (\"\\nDownloading MNIST data...\")\n",
        "  mnist = tf.keras.datasets.mnist\n",
        "  # Load data into trains\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "  x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "  return x_train, x_test, y_train, y_test"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elau4HSszz44",
        "colab_type": "text"
      },
      "source": [
        "### Model Creation Functions\n",
        "Develop models here. Note that you may have to create specific input/output layers here to match your dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSbF47jR4wcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pdb\n",
        "\n",
        "# Use this function to select one of the model creation functions\n",
        "def create_model():\n",
        "  return standardNN()\n",
        "\n",
        "# Standard Neural Network\n",
        "def standardNN():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucr9Yx4a8Qtu",
        "colab_type": "text"
      },
      "source": [
        "## Federated Learning Validation\n",
        "\n",
        "### Network Model\n",
        "Here we use nodes to carry models. The reason for doing this to prevent the instantiation of new models each time weights have to be transferred. Instead, the state of each model can be preserved in the node that it resides in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WJjvFBBEYs3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0bc1b28c-6366-47bf-b43a-e94b1a223c92"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pdb\n",
        "\n",
        "# Used to start execution ASAP\n",
        "# tf.enable_eager_execution()\n",
        "\n",
        "# Configuration\n",
        "num_clients = 8\n",
        "num_epochs = 2\n",
        "num_server_rounds = 8\n",
        "num_client_rounds = 4\n",
        "nonIID = False\n",
        "predeterminedSplit = True\n",
        "dataSplit = []\n",
        "print (\"Configuration:\" + \\\n",
        "       \"\\n\\t%d clients.\" % (num_clients) + \\\n",
        "       \"\\n\\t%d training epochs.\" % (num_epochs)  + \\\n",
        "       \"\\n\\tUsing %sIID data.\" % (\"non-\" if nonIID else \"\"))\n",
        "\n",
        "# Server class\n",
        "class Server:\n",
        "  def __init__(self, modelGenerator):\n",
        "    self.model = modelGenerator()\n",
        "    self.clients = []\n",
        "    self.neighbors = []\n",
        "# Client class\n",
        "class Client:\n",
        "  def __init__(self, modelGenerator):\n",
        "    self.model = modelGenerator()\n",
        "    self.neighbors = []\n",
        "    self.x_data = None\n",
        "    self.y_data = None\n",
        "    self.data_size = None\n",
        "  def plotAccuracy(self, histories):\n",
        "    # Compile histories\n",
        "    categorical_accuracy = []\n",
        "    val_categorical_accuracy = []\n",
        "    for history in histories:\n",
        "      categorical_accuracy = categorical_accuracy + history.history['acc']\n",
        "      # val_categorical_accuracy = val_categorical_accuracy + history.history['val_categorical_accuracy']\n",
        "    # The history of our accuracy during training.\n",
        "    plt.plot(categorical_accuracy)\n",
        "    plt.plot(val_categorical_accuracy)\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Number of epochs')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    return plt\n",
        "  def train(self):\n",
        "    history = self.model.fit(self.x_data, self.y_data, epochs=num_epochs)\n",
        "    # print(history.history.keys())\n",
        "    # self.accPlot = self.plotAccuracy([history])\n",
        "\n",
        "# Weight averaging\n",
        "def averageWeights(weightsList, weighting=None):\n",
        "  denominator = len(weightsList)\n",
        "  new_weights = []\n",
        "  if weighting is None:\n",
        "    # Handle IID data (balanced)\n",
        "    for part in range(len(weightsList[0])):\n",
        "      part_stack = [weights[part] for weights in weightsList]\n",
        "      new_stack = sum(part_stack) / denominator\n",
        "      new_stack = np.array(new_stack)\n",
        "      new_weights.append(new_stack)\n",
        "    return new_weights\n",
        "  else:\n",
        "    for part in range(len(weightsList[0])):\n",
        "      part_stack = [weights[part] for weights in weightsList]\n",
        "      # part_stack = np.array(part_stack) * weighting\n",
        "      for i in range(len(weighting)):\n",
        "        part_stack[i] = part_stack[i] * weighting[i]\n",
        "      new_stack = sum(part_stack)\n",
        "      new_stack = np.array(new_stack)\n",
        "      new_weights.append(new_stack)\n",
        "    return new_weights\n",
        "\n",
        "\n",
        "# Create the network\n",
        "print (\"\\nCreating a network...\")\n",
        "server = Server(create_model)\n",
        "for i in range(num_clients):\n",
        "  server.clients.append(Client(create_model))\n",
        "\n",
        "# Load data\n",
        "x_train, x_test, y_train, y_test = get_dataset()\n",
        "\n",
        "# Splitting the dataset for different clients\n",
        "print (\"\\nSplitting data into different clients...\")\n",
        "if nonIID:\n",
        "  print (\"\\tRandomly assigning ranges of data...\")\n",
        "  percentageMarkers = []\n",
        "  for i in range(num_clients-1):\n",
        "    percentageMarkers.append(random.random())\n",
        "  percentageMarkers.append(1.0)\n",
        "  percentageMarkers = sorted(percentageMarkers)\n",
        "else:\n",
        "  print (\"\\tUniformly assigning ranges of data\")\n",
        "  percentageMarkers = [1/num_clients * (n+1) for n in range(num_clients)]\n",
        "# Storing each subset of data in a client\n",
        "print (\"\\tStoring subsets of data into each client...\")\n",
        "xMarkers = [int(marker * len(x_train)) for marker in percentageMarkers]\n",
        "yMarkers = [int(marker * len(y_train)) for marker in percentageMarkers]\n",
        "for j in range(len(percentageMarkers)):\n",
        "  server.clients[j].x_data = x_train[(xMarkers[j-1] if j > 0 else 0):xMarkers[j]]\n",
        "  server.clients[j].y_data = y_train[(yMarkers[j-1] if j > 0 else 0):yMarkers[j]]\n",
        "  server.clients[j].data_size = len(server.clients[j].x_data)\n",
        "\n",
        "# Client data diagnostic\n",
        "print (\"\\nFinished setting up client data!\")\n",
        "for client in server.clients:\n",
        "  print (\"\\tClient %d:\\tX: %d\\tY: %d\" % (server.clients.index(client), len(client.x_data), len(client.y_data)))\n",
        "\n",
        "# Server action\n",
        "server_accuracies = []\n",
        "server_losses = []\n",
        "for server_round in range(num_server_rounds):\n",
        "  print(\"\\nSERVER ROUND \", server_round, \":\\n\")\n",
        "  # Save server model weights\n",
        "  global_weights = server.model.get_weights()\n",
        "  # Clients' actions\n",
        "  client_weight_list = []\n",
        "  for client in server.clients:\n",
        "    print(\"\\nCLIENT \", server.clients.index(client), \":\\n\")\n",
        "    # Initialize recorded weights\n",
        "    round_weight_list = []\n",
        "    for client_round in range(num_client_rounds):\n",
        "      # Accept global weights\n",
        "      client.model.set_weights(global_weights)\n",
        "      # Train\n",
        "      client.train()\n",
        "      # Record weights\n",
        "      round_weight_list.append(client.model.get_weights())\n",
        "    client_weight_list.append(averageWeights(round_weight_list))\n",
        "  client_data_sizes = [client.data_size for client in server.clients]\n",
        "  client_weighting = np.array(client_data_sizes) / sum(client_data_sizes)\n",
        "  server.model.set_weights(averageWeights(client_weight_list, weighting=client_weighting))\n",
        "  loss, acc = server.model.evaluate(x_test, y_test)\n",
        "  print(\"\\nSERVER ROUND \", server_round, \" ACCURACY: \", acc, \"\\n\")\n",
        "  server_accuracies.append(acc)\n",
        "  server_losses.append(loss)\n",
        "  print(\"FINAL RESULTS:\\nAccuracies: \", server_accuracies, \"\\nLoss: \", server_losses)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "235/235 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.8503\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 1.0547 - accuracy: 0.6804\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.8499\n",
            "\n",
            "CLIENT  6 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 1.0545 - accuracy: 0.6772\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.8428\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 1.0585 - accuracy: 0.6756\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.8424\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 1.0297 - accuracy: 0.6868\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.8436\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 1.0305 - accuracy: 0.6812\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.8491\n",
            "\n",
            "CLIENT  7 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.9708 - accuracy: 0.7237\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8720\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.9646 - accuracy: 0.7164\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.8648\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.9621 - accuracy: 0.7127\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.8699\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.9586 - accuracy: 0.7211\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8685\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3523 - accuracy: 0.9079\n",
            "\n",
            "SERVER ROUND  0  ACCURACY:  0.9078999757766724 \n",
            "\n",
            "FINAL RESULTS:\n",
            "Accuracies:  [0.9078999757766724] \n",
            "Loss:  [0.3522868752479553]\n",
            "\n",
            "SERVER ROUND  1 :\n",
            "\n",
            "\n",
            "CLIENT  0 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8817\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3472 - accuracy: 0.9019\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4196 - accuracy: 0.8801\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8991\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8777\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.9059\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4239 - accuracy: 0.8775\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3473 - accuracy: 0.8952\n",
            "\n",
            "CLIENT  1 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.8624\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8895\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8620\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3790 - accuracy: 0.8880\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.8584\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8848\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.8648\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8896\n",
            "\n",
            "CLIENT  2 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.8720\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8957\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8767\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3663 - accuracy: 0.8969\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.8768\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3645 - accuracy: 0.8933\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4324 - accuracy: 0.8739\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3711 - accuracy: 0.8944\n",
            "\n",
            "CLIENT  3 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.8629\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3646 - accuracy: 0.8873\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.8712\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3675 - accuracy: 0.8943\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.8653\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3659 - accuracy: 0.8884\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8687\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3677 - accuracy: 0.8887\n",
            "\n",
            "CLIENT  4 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.8660\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3868 - accuracy: 0.8873\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.8683\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3907 - accuracy: 0.8843\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.8667\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8855\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.8637\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3791 - accuracy: 0.8869\n",
            "\n",
            "CLIENT  5 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.8645\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8853\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8665\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8832\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.8633\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8837\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8653\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3867 - accuracy: 0.8868\n",
            "\n",
            "CLIENT  6 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8693\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3960 - accuracy: 0.8821\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8665\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3906 - accuracy: 0.8864\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.8629\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8824\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.8619\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8885\n",
            "\n",
            "CLIENT  7 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8837\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.9059\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8861\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.9068\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8901\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.9029\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3930 - accuracy: 0.8824\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.9021\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.2662 - accuracy: 0.9243\n",
            "\n",
            "SERVER ROUND  1  ACCURACY:  0.9243000149726868 \n",
            "\n",
            "FINAL RESULTS:\n",
            "Accuracies:  [0.9078999757766724, 0.9243000149726868] \n",
            "Loss:  [0.3522868752479553, 0.2662389576435089]\n",
            "\n",
            "SERVER ROUND  2 :\n",
            "\n",
            "\n",
            "CLIENT  0 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.9079\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3075 - accuracy: 0.9161\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3433 - accuracy: 0.9009\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3014 - accuracy: 0.9155\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.9036\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2978 - accuracy: 0.9156\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.9061\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.9125\n",
            "\n",
            "CLIENT  1 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3708 - accuracy: 0.8909\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.9007\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3737 - accuracy: 0.8931\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.9008\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8891\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.9032\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3768 - accuracy: 0.8892\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.9048\n",
            "\n",
            "CLIENT  2 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3543 - accuracy: 0.9001\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.9091\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8961\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3066 - accuracy: 0.9125\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3437 - accuracy: 0.9003\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.9116\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3553 - accuracy: 0.8976\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3100 - accuracy: 0.9119\n",
            "\n",
            "CLIENT  3 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8960\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.9088\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8952\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3191 - accuracy: 0.9044\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.8925\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.9047\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8932\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3177 - accuracy: 0.9025\n",
            "\n",
            "CLIENT  4 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8943\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.9033\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3650 - accuracy: 0.8916\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.9009\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3672 - accuracy: 0.8917\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.9015\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8911\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8988\n",
            "\n",
            "CLIENT  5 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8911\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.9020\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8959\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8988\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3688 - accuracy: 0.8923\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.9040\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3696 - accuracy: 0.8909\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.9012\n",
            "\n",
            "CLIENT  6 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8841\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.9041\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8868\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.9005\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3758 - accuracy: 0.8893\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.9003\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3724 - accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.9017\n",
            "\n",
            "CLIENT  7 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.9081\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2764 - accuracy: 0.9207\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3150 - accuracy: 0.9084\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2780 - accuracy: 0.9164\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3108 - accuracy: 0.9101\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2754 - accuracy: 0.9195\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3107 - accuracy: 0.9095\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2740 - accuracy: 0.9188\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.2305 - accuracy: 0.9317\n",
            "\n",
            "SERVER ROUND  2  ACCURACY:  0.9316999912261963 \n",
            "\n",
            "FINAL RESULTS:\n",
            "Accuracies:  [0.9078999757766724, 0.9243000149726868, 0.9316999912261963] \n",
            "Loss:  [0.3522868752479553, 0.2662389576435089, 0.2305079847574234]\n",
            "\n",
            "SERVER ROUND  3 :\n",
            "\n",
            "\n",
            "CLIENT  0 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2940 - accuracy: 0.9175\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2682 - accuracy: 0.9224\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.9136\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2700 - accuracy: 0.9221\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2947 - accuracy: 0.9141\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2676 - accuracy: 0.9253\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3010 - accuracy: 0.9169\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2712 - accuracy: 0.9227\n",
            "\n",
            "CLIENT  1 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.9009\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.9121\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.9044\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.9104\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.9017\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2961 - accuracy: 0.9095\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8999\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.9087\n",
            "\n",
            "CLIENT  2 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.9105\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2728 - accuracy: 0.9225\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.9084\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2852 - accuracy: 0.9172\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3067 - accuracy: 0.9089\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2782 - accuracy: 0.9184\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.9115\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2867 - accuracy: 0.9148\n",
            "\n",
            "CLIENT  3 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3111 - accuracy: 0.9073\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2826 - accuracy: 0.9148\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.9049\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.9149\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.9061\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2859 - accuracy: 0.9085\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.9067\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.9148\n",
            "\n",
            "CLIENT  4 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.9020\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 0.9105\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.9033\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2921 - accuracy: 0.9139\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.9027\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.9156\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.9016\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.9123\n",
            "\n",
            "CLIENT  5 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.9035\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 0.9101\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.9031\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.9113\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.9007\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.9135\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3211 - accuracy: 0.9041\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2910 - accuracy: 0.9131\n",
            "\n",
            "CLIENT  6 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.9017\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.9111\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.9029\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3043 - accuracy: 0.9108\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.9021\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3045 - accuracy: 0.9064\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8992\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2991 - accuracy: 0.9104\n",
            "\n",
            "CLIENT  7 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2737 - accuracy: 0.9180\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2484 - accuracy: 0.9255\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2774 - accuracy: 0.9177\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.9264\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2798 - accuracy: 0.9199\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.9287\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.9225\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2439 - accuracy: 0.9259\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.2077 - accuracy: 0.9373\n",
            "\n",
            "SERVER ROUND  3  ACCURACY:  0.9373000264167786 \n",
            "\n",
            "FINAL RESULTS:\n",
            "Accuracies:  [0.9078999757766724, 0.9243000149726868, 0.9316999912261963, 0.9373000264167786] \n",
            "Loss:  [0.3522868752479553, 0.2662389576435089, 0.2305079847574234, 0.2077086716890335]\n",
            "\n",
            "SERVER ROUND  4 :\n",
            "\n",
            "\n",
            "CLIENT  0 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.9183\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.9288\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.9213\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.9269\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.9220\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.9293\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.9243\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.9284\n",
            "\n",
            "CLIENT  1 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2991 - accuracy: 0.9115\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2761 - accuracy: 0.9149\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3002 - accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2722 - accuracy: 0.9180\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2947 - accuracy: 0.9151\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2749 - accuracy: 0.9165\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3019 - accuracy: 0.9105\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2738 - accuracy: 0.9180\n",
            "\n",
            "CLIENT  2 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2820 - accuracy: 0.9161\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2566 - accuracy: 0.9260\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2809 - accuracy: 0.9132\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2581 - accuracy: 0.9219\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2801 - accuracy: 0.9179\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2530 - accuracy: 0.9264\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2781 - accuracy: 0.9183\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.9264\n",
            "\n",
            "CLIENT  3 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2900 - accuracy: 0.9123\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.9191\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2888 - accuracy: 0.9137\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2590 - accuracy: 0.9188\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.9109\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.9209\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2883 - accuracy: 0.9149\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2653 - accuracy: 0.9193\n",
            "\n",
            "CLIENT  4 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3006 - accuracy: 0.9081\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2696 - accuracy: 0.9223\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2985 - accuracy: 0.9129\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.9185\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.9117\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2699 - accuracy: 0.9164\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2935 - accuracy: 0.9117\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2685 - accuracy: 0.9176\n",
            "\n",
            "CLIENT  5 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2958 - accuracy: 0.9123\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2720 - accuracy: 0.9188\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2982 - accuracy: 0.9109\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2782 - accuracy: 0.9145\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2979 - accuracy: 0.9129\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2694 - accuracy: 0.9179\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.9120\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2784 - accuracy: 0.9161\n",
            "\n",
            "CLIENT  6 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.3061 - accuracy: 0.9099\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2794 - accuracy: 0.9160\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.9125\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2735 - accuracy: 0.9195\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.9128\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2769 - accuracy: 0.9207\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.9060\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2746 - accuracy: 0.9176\n",
            "\n",
            "CLIENT  7 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2529 - accuracy: 0.9265\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2268 - accuracy: 0.9335\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2511 - accuracy: 0.9265\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2243 - accuracy: 0.9345\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.9284\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2249 - accuracy: 0.9343\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.9273\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2260 - accuracy: 0.9301\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.1909 - accuracy: 0.9443\n",
            "\n",
            "SERVER ROUND  4  ACCURACY:  0.9442999958992004 \n",
            "\n",
            "FINAL RESULTS:\n",
            "Accuracies:  [0.9078999757766724, 0.9243000149726868, 0.9316999912261963, 0.9373000264167786, 0.9442999958992004] \n",
            "Loss:  [0.3522868752479553, 0.2662389576435089, 0.2305079847574234, 0.2077086716890335, 0.19094422459602356]\n",
            "\n",
            "SERVER ROUND  5 :\n",
            "\n",
            "\n",
            "CLIENT  0 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2507 - accuracy: 0.9295\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2319 - accuracy: 0.9307\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.9285\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9307\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2541 - accuracy: 0.9285\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9363\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2558 - accuracy: 0.9237\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2311 - accuracy: 0.9332\n",
            "\n",
            "CLIENT  1 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2785 - accuracy: 0.9179\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2515 - accuracy: 0.9243\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2800 - accuracy: 0.9159\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2550 - accuracy: 0.9276\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2809 - accuracy: 0.9169\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.9225\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2820 - accuracy: 0.9135\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2515 - accuracy: 0.9251\n",
            "\n",
            "CLIENT  2 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2620 - accuracy: 0.9195\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.9275\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.9260\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2425 - accuracy: 0.9289\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2667 - accuracy: 0.9207\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2420 - accuracy: 0.9288\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.9267\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9329\n",
            "\n",
            "CLIENT  3 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2714 - accuracy: 0.9212\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.9253\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.9171\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.9255\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2714 - accuracy: 0.9164\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.9249\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2700 - accuracy: 0.9183\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.9251\n",
            "\n",
            "CLIENT  4 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2793 - accuracy: 0.9168\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2596 - accuracy: 0.9191\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.9140\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2621 - accuracy: 0.9228\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2813 - accuracy: 0.9160\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2578 - accuracy: 0.9228\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2731 - accuracy: 0.9176\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2524 - accuracy: 0.9232\n",
            "\n",
            "CLIENT  5 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2792 - accuracy: 0.9135\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2577 - accuracy: 0.9217\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2803 - accuracy: 0.9133\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2551 - accuracy: 0.9216\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2775 - accuracy: 0.9161\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2539 - accuracy: 0.9249\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2807 - accuracy: 0.9180\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2520 - accuracy: 0.9220\n",
            "\n",
            "CLIENT  6 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2876 - accuracy: 0.9181\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2549 - accuracy: 0.9248\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2870 - accuracy: 0.9171\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2568 - accuracy: 0.9233\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2874 - accuracy: 0.9105\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2588 - accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2838 - accuracy: 0.9176\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2619 - accuracy: 0.9219\n",
            "\n",
            "CLIENT  7 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.9317\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2105 - accuracy: 0.9376\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2303 - accuracy: 0.9328\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2092 - accuracy: 0.9376\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2307 - accuracy: 0.9327\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.9373\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.9340\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2040 - accuracy: 0.9400\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.9468\n",
            "\n",
            "SERVER ROUND  5  ACCURACY:  0.9467999935150146 \n",
            "\n",
            "FINAL RESULTS:\n",
            "Accuracies:  [0.9078999757766724, 0.9243000149726868, 0.9316999912261963, 0.9373000264167786, 0.9442999958992004, 0.9467999935150146] \n",
            "Loss:  [0.3522868752479553, 0.2662389576435089, 0.2305079847574234, 0.2077086716890335, 0.19094422459602356, 0.17914935946464539]\n",
            "\n",
            "SERVER ROUND  6 :\n",
            "\n",
            "\n",
            "CLIENT  0 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2432 - accuracy: 0.9273\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.9377\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9283\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9341\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.9289\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2247 - accuracy: 0.9333\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2414 - accuracy: 0.9287\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9335\n",
            "\n",
            "CLIENT  1 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2668 - accuracy: 0.9215\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.9281\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2674 - accuracy: 0.9209\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2376 - accuracy: 0.9273\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2670 - accuracy: 0.9207\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2385 - accuracy: 0.9269\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.9187\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.9257\n",
            "\n",
            "CLIENT  2 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.9279\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.9353\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.9247\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2323 - accuracy: 0.9319\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2431 - accuracy: 0.9275\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2324 - accuracy: 0.9293\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.9248\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2216 - accuracy: 0.9377\n",
            "\n",
            "CLIENT  3 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2549 - accuracy: 0.9195\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9291\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.9253\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2342 - accuracy: 0.9291\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2501 - accuracy: 0.9244\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2299 - accuracy: 0.9291\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 0.9220\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.9293\n",
            "\n",
            "CLIENT  4 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2710 - accuracy: 0.9203\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.9281\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2663 - accuracy: 0.9219\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.9277\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2637 - accuracy: 0.9197\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2392 - accuracy: 0.9261\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2618 - accuracy: 0.9229\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2398 - accuracy: 0.9276\n",
            "\n",
            "CLIENT  5 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2604 - accuracy: 0.9211\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.9225\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.9208\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2446 - accuracy: 0.9255\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2595 - accuracy: 0.9243\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2410 - accuracy: 0.9252\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2698 - accuracy: 0.9179\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.9279\n",
            "\n",
            "CLIENT  6 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2662 - accuracy: 0.9189\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9237\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2732 - accuracy: 0.9208\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.9245\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2689 - accuracy: 0.9208\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2442 - accuracy: 0.9260\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2730 - accuracy: 0.9141\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.9316\n",
            "\n",
            "CLIENT  7 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.9345\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.1943 - accuracy: 0.9427\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9351\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.9416\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2190 - accuracy: 0.9349\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9429\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2237 - accuracy: 0.9341\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9411\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.1700 - accuracy: 0.9480\n",
            "\n",
            "SERVER ROUND  6  ACCURACY:  0.9480000138282776 \n",
            "\n",
            "FINAL RESULTS:\n",
            "Accuracies:  [0.9078999757766724, 0.9243000149726868, 0.9316999912261963, 0.9373000264167786, 0.9442999958992004, 0.9467999935150146, 0.9480000138282776] \n",
            "Loss:  [0.3522868752479553, 0.2662389576435089, 0.2305079847574234, 0.2077086716890335, 0.19094422459602356, 0.17914935946464539, 0.16997098922729492]\n",
            "\n",
            "SERVER ROUND  7 :\n",
            "\n",
            "\n",
            "CLIENT  0 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2347 - accuracy: 0.9291\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2072 - accuracy: 0.9388\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.9316\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2158 - accuracy: 0.9363\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.9331\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2098 - accuracy: 0.9381\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2304 - accuracy: 0.9311\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2044 - accuracy: 0.9423\n",
            "\n",
            "CLIENT  1 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2521 - accuracy: 0.9243\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.9300\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2498 - accuracy: 0.9259\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2352 - accuracy: 0.9289\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2567 - accuracy: 0.9247\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2337 - accuracy: 0.9307\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2558 - accuracy: 0.9245\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.9284\n",
            "\n",
            "CLIENT  2 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2392 - accuracy: 0.9288\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.9359\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2394 - accuracy: 0.9271\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2158 - accuracy: 0.9347\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2420 - accuracy: 0.9293\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.9333\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2433 - accuracy: 0.9313\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.9355\n",
            "\n",
            "CLIENT  3 :\n",
            "\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2408 - accuracy: 0.9261\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.9328\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.9247\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.9324\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.9267\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 0s 1ms/step - loss: 0.2162 - accuracy: 0.9329\n",
            "Epoch 1/2\n",
            " 74/235 [========>.....................] - ETA: 0s - loss: 0.2561 - accuracy: 0.9248"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-783a35ce5fa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m       \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m       \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m       \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m       \u001b[0;31m# Record weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m       \u001b[0mround_weight_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-783a35ce5fa8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;31m# print(history.history.keys())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# self.accPlot = self.plotAccuracy([history])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0mhook_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'on_{mode}_batch_{hook}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_t_enter_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFNtu_EoZI9q",
        "colab_type": "text"
      },
      "source": [
        "## Decentralized Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFxk_AzpZObH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pdb\n",
        "\n",
        "# Used to start execution ASAP\n",
        "# tf.enable_eager_execution()\n",
        "\n",
        "# Configuration\n",
        "num_clients = 8\n",
        "num_epochs = 2\n",
        "num_learning_rounds = 16\n",
        "num_client_rounds = 1\n",
        "link_reliability = 0.75\n",
        "nonIID = False\n",
        "print (\"Configuration:\" + \\\n",
        "       \"\\n\\t%d clients.\" % (num_clients) + \\\n",
        "       \"\\n\\t%d training epochs.\" % (num_epochs)  + \\\n",
        "       \"\\n\\tUsing %sIID data.\" % (\"non-\" if nonIID else \"\"))\n",
        "\n",
        "# Client class\n",
        "class Client:\n",
        "  def __init__(self, modelGenerator):\n",
        "    self.model = modelGenerator()\n",
        "    self.neighbors = []\n",
        "    self.x_data = None\n",
        "    self.y_data = None\n",
        "    self.data_size = None\n",
        "    self.accuracy_history = []\n",
        "    self.loss_history = []\n",
        "  def plotAccuracy(self, histories):\n",
        "    # Compile histories\n",
        "    categorical_accuracy = []\n",
        "    val_categorical_accuracy = []\n",
        "    for history in histories:\n",
        "      categorical_accuracy = categorical_accuracy + history.history['acc']\n",
        "    # The history of our accuracy during training.\n",
        "    plt.plot(categorical_accuracy)\n",
        "    plt.plot(val_categorical_accuracy)\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Number of epochs')\n",
        "    plt.legend(['train', 'validation'], loc='upper left')\n",
        "    return plt\n",
        "  def train(self):\n",
        "    history = self.model.fit(self.x_data, self.y_data, epochs=num_epochs)\n",
        "    self.setOutgoingMessage()\n",
        "    # print(history.history.keys())\n",
        "    # self.accPlot = self.plotAccuracy([history])\n",
        "  def test(self, x, y):\n",
        "    loss, acc = self.model.evaluate(x, y, verbose=1)\n",
        "    self.accuracy_history.append(acc)\n",
        "    self.loss_history.append(loss)\n",
        "    return loss, acc\n",
        "  def setOutgoingMessage(self):\n",
        "    self.outgoing_message = (self.data_size, self.model.get_weights())\n",
        "  def communityLearn(self):\n",
        "    # Accept incoming messages\n",
        "    incoming_messages = []\n",
        "    for neighbor in self.neighbors:\n",
        "      # Link reliability functionality\n",
        "      r = random.random()\n",
        "      if (r <= link_reliability) or (clientList.index(neighbor) == clientList.index(self)):\n",
        "        incoming_messages.append(neighbor.outgoing_message)\n",
        "    # Grab sizes, set ratios, grab weights\n",
        "    ordered_sizes = [message[0] for message in incoming_messages]\n",
        "    ordered_sizes = np.array(ordered_sizes) / sum(ordered_sizes)\n",
        "    ordered_weights = [message[1] for message in incoming_messages]\n",
        "    # Compute new weights\n",
        "    new_weights = averageWeights(ordered_weights, ordered_sizes)\n",
        "    # Create new model with appropriate weights\n",
        "    self.model = create_model()\n",
        "    self.model.set_weights(new_weights)\n",
        "\n",
        "# Weight averaging\n",
        "def averageWeights(weightsList, weighting=None):\n",
        "  denominator = len(weightsList)\n",
        "  new_weights = []\n",
        "  if weighting is None:\n",
        "    # Handle IID data (balanced)\n",
        "    for part in range(len(weightsList[0])):\n",
        "      part_stack = [weights[part] for weights in weightsList]\n",
        "      new_stack = sum(part_stack) / denominator\n",
        "      new_stack = np.array(new_stack)\n",
        "      new_weights.append(new_stack)\n",
        "    return new_weights\n",
        "  else:\n",
        "    for part in range(len(weightsList[0])):\n",
        "      part_stack = [weights[part] for weights in weightsList]\n",
        "      # part_stack = np.array(part_stack) * weighting\n",
        "      for i in range(len(weighting)):\n",
        "        part_stack[i] = part_stack[i] * weighting[i]\n",
        "      new_stack = sum(part_stack)\n",
        "      new_stack = np.array(new_stack)\n",
        "      new_weights.append(new_stack)\n",
        "    return new_weights\n",
        "\n",
        "\n",
        "# # Create a strongly connected network\n",
        "# print (\"\\nCreating a network...\")\n",
        "# clientList = []\n",
        "# for i in range(num_clients):\n",
        "#   clientList.append(Client(create_model))\n",
        "# # Add neighbors\n",
        "# for client in clientList:\n",
        "#   for neighbor in clientList:\n",
        "#     client.neighbors.append(neighbor)\n",
        "\n",
        "# Create a weakly connected network\n",
        "print (\"\\nCreating a weakly connected network...\")\n",
        "clientList = []\n",
        "for i in range(8):\n",
        "  clientList.append(Client(create_model))\n",
        "# Add linkings\n",
        "clientList[0].neighbors += [clientList[0], clientList[2], clientList[3], clientList[4]]\n",
        "clientList[1].neighbors += [clientList[1], clientList[2]]\n",
        "clientList[2].neighbors += [clientList[0], clientList[1], clientList[2], clientList[3]]\n",
        "clientList[3].neighbors += [clientList[0], clientList[2], clientList[3], clientList[4], clientList[7]]\n",
        "clientList[4].neighbors += [clientList[0], clientList[3], clientList[4], clientList[5], clientList[6], clientList[7]]\n",
        "clientList[5].neighbors += [clientList[4], clientList[5], clientList[6]]\n",
        "clientList[6].neighbors += [clientList[4], clientList[5], clientList[6], clientList[7]]\n",
        "clientList[7].neighbors += [clientList[3], clientList[4], clientList[6], clientList[7]]\n",
        "\n",
        "# Load data\n",
        "x_train, x_test, y_train, y_test = get_dataset()\n",
        "\n",
        "# Splitting the dataset for different clients\n",
        "print (\"\\nSplitting data into different clients...\")\n",
        "if nonIID:\n",
        "  print (\"\\tRandomly assigning ranges of data...\")\n",
        "  percentageMarkers = []\n",
        "  for i in range(num_clients-1):\n",
        "    percentageMarkers.append(random.random())\n",
        "  percentageMarkers.append(1.0)\n",
        "  percentageMarkers = sorted(percentageMarkers)\n",
        "else:\n",
        "  print (\"\\tUniformly assigning ranges of data\")\n",
        "  percentageMarkers = [1/num_clients * (n+1) for n in range(num_clients)]\n",
        "# Storing each subset of data in a client\n",
        "print (\"\\tStoring subsets of data into each client...\")\n",
        "xMarkers = [int(marker * len(x_train)) for marker in percentageMarkers]\n",
        "yMarkers = [int(marker * len(y_train)) for marker in percentageMarkers]\n",
        "for j in range(len(percentageMarkers)):\n",
        "  clientList[j].x_data = x_train[(xMarkers[j-1] if j > 0 else 0):xMarkers[j]]\n",
        "  clientList[j].y_data = y_train[(yMarkers[j-1] if j > 0 else 0):yMarkers[j]]\n",
        "  clientList[j].data_size = len(clientList[j].x_data)\n",
        "\n",
        "# Client data diagnostic\n",
        "print (\"\\nFinished setting up client data!\")\n",
        "for client in clientList:\n",
        "  print (\"\\tClient %d:\\tX: %d\\tY: %d\" % (clientList.index(client), len(client.x_data), len(client.y_data)))\n",
        "\n",
        "for learning_round in range(num_learning_rounds):\n",
        "  print(\"\\nLEARNING ROUND \", learning_round, \":\\n\")\n",
        "  # Have each client learn on its data\n",
        "  for client in clientList:\n",
        "    print (\"\\nROUND\", learning_round, \", CLIENT\", clientList.index(client), \"TRAINING\\n\")\n",
        "    client.train()\n",
        "  # Communicate and learn\n",
        "  for client in clientList:\n",
        "    print (\"\\nROUND\", learning_round, \", CLIENT\", clientList.index(client), \"LEARNING\\n\")\n",
        "    client.communityLearn()\n",
        "  # Test at the end of this round\n",
        "  for client in clientList:\n",
        "    print (\"\\nROUND\", learning_round, \", CLIENT\", clientList.index(client), \"TESTING\\n\")\n",
        "    client.test(x_test, y_test)\n",
        "# Print out results\n",
        "for client in clientList:\n",
        "  print(\"Client \", clientList.index(client), \":\\n\")\n",
        "  print(\"\\tAccuracy History: \", client.accuracy_history, \"\\n\")\n",
        "  print(\"\\tLoss History: \", client.loss_history, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}